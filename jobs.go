package main

import (
	"TL-Data-Collector/entity"
	"TL-Data-Collector/log"
	"TL-Data-Collector/proto/gateway"
	"context"
	"encoding/json"
	"errors"
	"fmt"
	"io/ioutil"
	"path"
	"runtime"
	"strings"
	"syscall"
	"time"

	"golang.org/x/sys/windows"
)

const (
	// Rfc3339Milli unified time format, refer to time.RFC3339Nano
	Rfc3339Milli = "2006-01-02T15:04:05.999Z07:00"
)

var (
	// arrary of export types, currently only "data" is supported, in future there might be DOM
	exportTypes = []string{"data"}
)

const (
	// DefaultGRPCTimeout - default timeout for sending grpc messages
	DefaultGRPCTimeout = 5
)

// report data by the grpc connection
func (p *Program) report(token string, v interface{}) error {
	// marshal the value to json
	data, err := json.Marshal(v)
	if err != nil {
		return err
	}

	// context with timeout
	ctx, cancel := context.WithTimeout(context.Background(), time.Second*DefaultGRPCTimeout)
	defer cancel()

	// prepare the request
	request := gateway.ReportRequest{
		Token: token,
		Data:  data,
	}
	reply, err := p.reportClient.Report(ctx, &request)
	if err != nil {
		return err
	}
	if reply.Status != gateway.Status_Success {
		return fmt.Errorf("the response status: %v", reply.Status)
	}

	return nil
}

func (p *Program) loadToken() (string, error) {
	// read token file
	token, err := ioutil.ReadFile(p.settings.App.BaseDir + tokenPath)
	if err != nil {
		log.Errorf("read token file: %v", err)
		return "", err
	}
	return string(token), nil
}

// load userid and uuid from files every time
func (p *Program) load() (string, string) {
	// read credential
	credential, err := ioutil.ReadFile(p.settings.App.BaseDir + credPath)
	if err != nil {
		log.Errorf("read credential file: %v", err)
		runtime.Goexit()
	}

	// read uuid file
	uuid, err := ioutil.ReadFile(p.settings.App.BaseDir + uuidPath)
	if err != nil {
		log.Errorf("read uuid file: %v", err)
		runtime.Goexit()
	}

	return string(credential), string(uuid)
}

// write a heartbeat message to gateway
func (p *Program) heartbeat() {
	log.Info("heartbeat report - start")

	// load the login id, uuid and token every time
	login, uuid := p.load()

	// create the heartbeat data
	hearbeat := entity.Heartbeat{
		Kind:   "data_heartbeat",
		Action: "insert",
		UserID: login,
		Source: uuid,
		Path:   "&&heartbeat",
		Data: entity.HeartbeatData{
			Status: "OK",
		},
		Timestamp: time.Now().Format(Rfc3339Milli),
	}

	// try send the data to gateway
	if err := p.flush(&hearbeat); err != nil {
		log.Errorf("send data to gateway, data: %v, error: %v", hearbeat, err)
	}

	log.Info("heartbeat report - end")
}

// whether the slice contains the target string or not
func contains(ss []string, target string) bool {
	b := false
	for _, s := range ss {
		if s == target {
			b = true
			break
		}
	}
	return b
}

func (p *Program) dataFolder() (string, error) {
	// parse the data folder path
	folder, err := ioutil.ReadFile(p.settings.App.BaseDir + dataPath)
	if err != nil {
		return "", err
	}
	return string(folder), nil
}

// parse the valid data files
func (p *Program) parse(folder string) ([]string, error) {
	// collect the names of json files in data folder
	files, err := ioutil.ReadDir(folder)
	if err != nil {
		return nil, err
	}
	jsons := make([]string, 0, maxNumOfFiles)
	for _, file := range files {
		name := file.Name()
		if path.Ext(name) == ".json" {
			jsons = append(jsons, name)
		}
	}

	// whether the lock is for all
	lock := false
	// the types that have been locked
	lockTypes := make([]string, 0, len(exportTypes))
	// the other json files
	dataFiles := make([]string, 0, maxNumOfFiles)
	for _, name := range jsons {
		fn := strings.Split(name, ".")[0]
		// check if it's lock file
		if strings.HasPrefix(fn, "lock") {
			locks := strings.Split(fn, "-")
			if len(locks) == 1 {
				lock = true // lock file
			} else {
				// lock-xx.json
				if len(locks) == 2 {
					l := strings.ToLower(locks[1])
					// lock-data.json
					if contains(exportTypes, l) {
						// append it to lock types only if it is a supported export type
						lockTypes = append(lockTypes, l)
					}
				}
			}
		} else {
			pieces := strings.Split(fn, "_")
			// a valid name should be split into 3 pieces by underscore sign
			// <export>_<app>_<unique timestamp>.json
			if len(pieces) == 3 {
				dataFiles = append(dataFiles, name)
			}
		}
	}
	if lock == true {
		log.Info("lock.json is in the data folder")
		return nil, nil

	}

	// get valid json files for processing, filter by export type and lock
	vfs := make([]string, 0, maxNumOfFiles)
	// <export>_<app>_<unique timestamp>.json
	for _, f := range dataFiles {
		// convert to lower case
		export := strings.ToLower(strings.Split(f, "_")[0])
		if !contains(exportTypes, export) {
			log.Infof("%s is skipped. It's export type is not supported", f)
		} else if contains(lockTypes, export) {
			log.Infof("%s is skipped. It's export type is locked", f)
		} else {
			// if the export is a supported type and not locked by lock-xx.json, then append it to valid file list
			vfs = append(vfs, f)
		}
	}

	return vfs, nil
}

func validate(m *entity.Message) error {
	if m.Kind == "" {
		return errors.New("dtype is empty")
	}
	if m.Action != "insert" && m.Action != "update" {
		return fmt.Errorf("invalid action: %v", m.Action)
	}
	if m.Source == "" {
		return errors.New("source is empty")
	}
	if m.Path == "" {
		return errors.New("path is empty")
	}
	if m.Time == "" {
		return errors.New("time is empty")
	}
	if len(m.Data) == 0 {
		return errors.New("data is empty")
	}

	return nil
}

// flush the message to gateway
func (p *Program) flush(v interface{}) error {
	// refresh the token
	token, err := p.loadToken()
	if err != nil {
		return err
	}

	// try send the data to gateway
	return p.report(token, v)
}

// transfer the data
func (p *Program) transfer(name string, data []byte, login string) error {
	var msgs []entity.Message

	// unmarshal the bytes to message structure
	if err := json.Unmarshal(data, &msgs); err != nil {
		return err
	}

	for index, msg := range msgs {
		// check whether data field is a valid json string
		if err := validate(&msg); err != nil {
			log.Errorf("message is invalid, file: %s index: %d, data: %s, error: %v", name, index, msg, err)
			continue
		}

		// these two fields are provided by collector
		msg.UserID = login
		msg.Timestamp = time.Now().Format(Rfc3339Milli)

		for {
			// try send the data to gateway
			if err := p.flush(&msg); err != nil {
				log.Errorf("send data to gateway, file: %s index: %d, data: %v, error: %v", name, index, msg, err)

				// retry again until sending success
				time.Sleep(2 * time.Second)
				continue
			}

			break
		}
	}

	return nil
}

// process the data file
func (p *Program) process(folder string, name string, login string) {
	// concatenate data folder and json file name
	fullpath := folder + "\\" + name
	path, err := syscall.UTF16PtrFromString(fullpath)
	if err != nil {
		return
	}

	// try to open this file exclusively by windows api, see https://golang.org/src/syscall/syscall_windows.go#L248
	handle, err := windows.CreateFile(path, syscall.GENERIC_READ, 0, nil, syscall.OPEN_EXISTING, syscall.FILE_ATTRIBUTE_NORMAL, 0)
	if err != nil {
		log.Infof("%s in use by another process", name)
	} else {
		log.Infof("%s can be opened in exclusive mode", name)

		var done uint32
		data := make([]byte, maxFileSize)
		// read from the file
		windows.ReadFile(handle, data, &done, nil)
		// trim slice to the number of bytes that have been read
		data = data[:done]

		// transfer the messages to gateway
		if err := p.transfer(name, data, login); err != nil {
			log.Errorf("error occurs in processing file %s: %v", name, err)
		}

		// close the file first
		windows.CloseHandle(handle)
		// delete the json file
		windows.DeleteFile(path)
	}
}

// collecting messages from data folder and sending to gateway
func (p *Program) collect() {
	// load the login id, uuid every time
	login, _ := p.load()

	log.Info("data collecting - start")

	// retrieve the data folder
	folder, err := p.dataFolder()
	if err != nil {
		log.Errorf("parse to retrieve files: %v", err)
		return
	}

	// parse the valid data files
	files, err := p.parse(folder)
	if err != nil {
		log.Errorf("parse to retrieve files: %v", err)
		return
	}
	if len(files) == 0 {
		log.Info("no files to process")
		return
	}

	// handle the data files one bye one
	for _, file := range files {
		p.process(folder, file, login)
	}

	// handle the files
	log.Info("data collecting - end")
}
